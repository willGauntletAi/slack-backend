I'm creating a slack clone. My first step is to determine how my relational data should be modeled. I'm planning on storing all persistient data in postgres.
Can you give me an initial list of tables and their columns?

Here's a basic structure:

users
- id (PK)
- username
- email
- password_hash
- created_at

workspaces
- id (PK)
- name
- created_at

channels
- id (PK)
- workspace_id (FK)
- name
- is_private
- created_at

messages
- id (PK)
- channel_id (FK)
- user_id (FK)
- content
- created_at

workspace_members
- workspace_id (FK)
- user_id (FK)
- role
- joined_at

channel_members
- channel_id (FK)
- user_id (FK)
- joined_at

Need anything else?

What about direct messages?

Add these tables:

direct_message_channels
- id (PK)
- created_at

direct_message_members
- channel_id (FK)
- user_id (FK)
- joined_at

direct_messages
- id (PK)
- channel_id (FK)
- user_id (FK)
- content
- created_at

Consider adding:
- deleted_at columns for soft deletion
- updated_at timestamps
- message thread support
- message reactions

Let's add your 4 suggestions as well then:

Here's all tables with those additions:

users
- id (PK)
- username
- email
- password_hash
- created_at
- updated_at
- deleted_at

workspaces
- id (PK)
- name
- created_at
- updated_at
- deleted_at

channels
- id (PK)
- workspace_id (FK)
- name
- is_private
- created_at
- updated_at
- deleted_at

messages
- id (PK)
- channel_id (FK)
- user_id (FK)
- parent_id (FK, self-reference for threads)
- content
- created_at
- updated_at
- deleted_at

workspace_members
- workspace_id (FK)
- user_id (FK)
- role
- joined_at
- updated_at
- deleted_at

channel_members
- channel_id (FK)
- user_id (FK)
- joined_at
- updated_at
- deleted_at

direct_message_channels
- id (PK)
- created_at
- updated_at
- deleted_at

direct_message_members
- channel_id (FK)
- user_id (FK)
- joined_at
- updated_at
- deleted_at

direct_messages
- id (PK)
- channel_id (FK)
- user_id (FK)
- parent_id (FK, self-reference for threads)
- content
- created_at
- updated_at
- deleted_at

message_reactions
- id (PK)
- message_id (FK)
- user_id (FK)
- emoji
- created_at


I think that looks good. Can you create a kysely migration for that?

Here's a migration using Kysely:

```typescript
import { Kysely, sql } from 'kysely'

export async function up(db: Kysely<any>) {
  await db.schema
    .createTable('users')
    .addColumn('id', 'uuid', col => col.primaryKey().defaultTo(sql`gen_random_uuid()`))
    .addColumn('username', 'varchar', col => col.notNull().unique())
    .addColumn('email', 'varchar', col => col.notNull().unique())
    .addColumn('password_hash', 'varchar', col => col.notNull())
    .addColumn('created_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('updated_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('deleted_at', 'timestamp')
    .execute()

  // Continue with other tables...
  // Want me to show the rest?
}

export async function down(db: Kysely<any>) {
  // Drop tables in reverse order due to foreign keys
  await db.schema.dropTable('message_reactions').execute()
  await db.schema.dropTable('direct_messages').execute()
  // etc...
}
```

Want the full migration?

Yes. Please give me the full file for all the tables.

```typescript
import { Kysely, sql } from 'kysely'

export async function up(db: Kysely<any>) {
  await db.schema
    .createTable('users')
    .addColumn('id', 'uuid', col => col.primaryKey().defaultTo(sql`gen_random_uuid()`))
    .addColumn('username', 'varchar', col => col.notNull().unique())
    .addColumn('email', 'varchar', col => col.notNull().unique())
    .addColumn('password_hash', 'varchar', col => col.notNull())
    .addColumn('created_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('updated_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('deleted_at', 'timestamp')
    .execute()

  await db.schema
    .createTable('workspaces')
    .addColumn('id', 'uuid', col => col.primaryKey().defaultTo(sql`gen_random_uuid()`))
    .addColumn('name', 'varchar', col => col.notNull())
    .addColumn('created_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('updated_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('deleted_at', 'timestamp')
    .execute()

  await db.schema
    .createTable('channels')
    .addColumn('id', 'uuid', col => col.primaryKey().defaultTo(sql`gen_random_uuid()`))
    .addColumn('workspace_id', 'uuid', col => col.references('workspaces.id').onDelete('cascade').notNull())
    .addColumn('name', 'varchar', col => col.notNull())
    .addColumn('is_private', 'boolean', col => col.notNull().defaultTo(false))
    .addColumn('created_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('updated_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('deleted_at', 'timestamp')
    .execute()

  await db.schema
    .createTable('messages')
    .addColumn('id', 'uuid', col => col.primaryKey().defaultTo(sql`gen_random_uuid()`))
    .addColumn('channel_id', 'uuid', col => col.references('channels.id').onDelete('cascade').notNull())
    .addColumn('user_id', 'uuid', col => col.references('users.id').onDelete('cascade').notNull())
    .addColumn('parent_id', 'uuid', col => col.references('messages.id').onDelete('cascade'))
    .addColumn('content', 'text', col => col.notNull())
    .addColumn('created_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('updated_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('deleted_at', 'timestamp')
    .execute()

  await db.schema
    .createTable('workspace_members')
    .addColumn('workspace_id', 'uuid', col => col.references('workspaces.id').onDelete('cascade').notNull())
    .addColumn('user_id', 'uuid', col => col.references('users.id').onDelete('cascade').notNull())
    .addColumn('role', 'varchar', col => col.notNull())
    .addColumn('joined_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('updated_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('deleted_at', 'timestamp')
    .addPrimaryKey(['workspace_id', 'user_id'])
    .execute()

  await db.schema
    .createTable('channel_members')
    .addColumn('channel_id', 'uuid', col => col.references('channels.id').onDelete('cascade').notNull())
    .addColumn('user_id', 'uuid', col => col.references('users.id').onDelete('cascade').notNull())
    .addColumn('joined_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('updated_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('deleted_at', 'timestamp')
    .addPrimaryKey(['channel_id', 'user_id'])
    .execute()

  await db.schema
    .createTable('direct_message_channels')
    .addColumn('id', 'uuid', col => col.primaryKey().defaultTo(sql`gen_random_uuid()`))
    .addColumn('created_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('updated_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('deleted_at', 'timestamp')
    .execute()

  await db.schema
    .createTable('direct_message_members')
    .addColumn('channel_id', 'uuid', col => col.references('direct_message_channels.id').onDelete('cascade').notNull())
    .addColumn('user_id', 'uuid', col => col.references('users.id').onDelete('cascade').notNull())
    .addColumn('joined_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('updated_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('deleted_at', 'timestamp')
    .addPrimaryKey(['channel_id', 'user_id'])
    .execute()

  await db.schema
    .createTable('direct_messages')
    .addColumn('id', 'uuid', col => col.primaryKey().defaultTo(sql`gen_random_uuid()`))
    .addColumn('channel_id', 'uuid', col => col.references('direct_message_channels.id').onDelete('cascade').notNull())
    .addColumn('user_id', 'uuid', col => col.references('users.id').onDelete('cascade').notNull())
    .addColumn('parent_id', 'uuid', col => col.references('direct_messages.id').onDelete('cascade'))
    .addColumn('content', 'text', col => col.notNull())
    .addColumn('created_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('updated_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .addColumn('deleted_at', 'timestamp')
    .execute()

  await db.schema
    .createTable('message_reactions')
    .addColumn('id', 'uuid', col => col.primaryKey().defaultTo(sql`gen_random_uuid()`))
    .addColumn('message_id', 'uuid', col => col.references('messages.id').onDelete('cascade').notNull())
    .addColumn('user_id', 'uuid', col => col.references('users.id').onDelete('cascade').notNull())
    .addColumn('emoji', 'varchar', col => col.notNull())
    .addColumn('created_at', 'timestamp', col => col.defaultTo(sql`now()`).notNull())
    .execute()
}

export async function down(db: Kysely<any>) {
  await db.schema.dropTable('message_reactions').execute()
  await db.schema.dropTable('direct_messages').execute()
  await db.schema.dropTable('direct_message_members').execute()
  await db.schema.dropTable('direct_message_channels').execute()
  await db.schema.dropTable('channel_members').execute()
  await db.schema.dropTable('workspace_members').execute()
  await db.schema.dropTable('messages').execute()
  await db.schema.dropTable('channels').execute()
  await db.schema.dropTable('workspaces').execute()
  await db.schema.dropTable('users').execute()
}
```

I just realized that you are using uuid's for the message id. Can we instead use something that will sort the messages by date created?

Use BIGSERIAL for messages. Here's the modified tables that need changing:

```typescript
// For messages table:
.addColumn('id', 'bigserial', col => col.primaryKey())

// For direct_messages table:
.addColumn('id', 'bigserial', col => col.primaryKey())

// Update message_reactions to reference bigint instead of uuid:
.addColumn('message_id', 'bigint', col => col.references('messages.id').onDelete('cascade').notNull())
```

Keep UUID for users, workspaces, channels, and DM channels.

Note I was assuming we would want to use something like ulid, but bigserial will work fine since we aren't doing any type of sharding and can just rely on the database to give us ordered keys without conflicts


